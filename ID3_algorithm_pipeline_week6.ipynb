{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff98d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c221c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data\n",
    "company_data = pd.read_csv('Company_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce9b3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>Bad</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120       Bad   42   \n",
       "1  11.22        111      48           16         260     83      Good   65   \n",
       "2  10.06        113      35           10         269     80    Medium   59   \n",
       "3   7.40        117     100            4         466     97    Medium   55   \n",
       "4   4.15        141      64            3         340    128       Bad   38   \n",
       "\n",
       "   Education Urban   US  \n",
       "0         17   Yes  Yes  \n",
       "1         10   Yes  Yes  \n",
       "2         12   Yes  Yes  \n",
       "3         14   Yes  Yes  \n",
       "4         13   Yes   No  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece89a8",
   "metadata": {},
   "source": [
    "###### Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafb42ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User defined fuction to check for null values\n",
    "\"\"\"This defines the function check_null_values with two arguments: \n",
    "the dataset 'data' and the list of special characters to treat as null values 'null_values'.\"\"\"\n",
    "def check_null_values_all_cols(data, null_values):\n",
    "    num_cols = len(data[0])\n",
    "    # iterates over each column in the dataset using the 'range' object 'num_cols'\n",
    "    for col_idx in range(num_cols):\n",
    "        null_found = False\n",
    "        for row in data:\n",
    "            value = row[col_idx]\n",
    "            if value is None or str(value).strip() in null_values:\n",
    "                null_found = True\n",
    "                break\n",
    "        if null_found:\n",
    "            print(f\"Null value found in column {col_idx}!\")\n",
    "        else:\n",
    "            print(f\"No null values found in column {col_idx}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9130ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImputer():\n",
    "    def __init__(self, col_idx, strategy, null_values=[\"\", \"NA\", \"Na\", \"nA\", \"na\", \"N/A\", \"N/a\", \"n/A\", \"n/a\"]):\n",
    "        self.col_idx = col_idx\n",
    "        self.strategy = strategy\n",
    "        self.null_values = null_values\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        col = [row[self.col_idx] for row in X if row[self.col_idx] not in self.null_values]\n",
    "        if self.strategy == \"mean\":\n",
    "            val = sum(col) / len(col)\n",
    "        elif self.strategy == \"median\":\n",
    "            col.sort()\n",
    "            mid = len(col) // 2\n",
    "            if len(col) % 2 == 0:\n",
    "                val = (col[mid-1] + col[mid]) / 2\n",
    "            else:\n",
    "                val = col[mid]\n",
    "        elif self.strategy == \"mode\":\n",
    "            val = max(set(col), key = col.count)\n",
    "        for j in range(len(X)):\n",
    "            if X[j][self.col_idx] in self.null_values:\n",
    "                X[j][self.col_idx] = val\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365262db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierTreatment():\n",
    "    def __init__(self, method='iqr', multiplier=1.5):\n",
    "        self.method = method\n",
    "        self.multiplier = multiplier\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.method == 'iqr':\n",
    "            Q1 = np.percentile(X, 25, axis=0)\n",
    "            Q3 = np.percentile(X, 75, axis=0)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - self.multiplier * IQR\n",
    "            upper = Q3 + self.multiplier * IQR\n",
    "            return np.clip(X, lower, upper)\n",
    "        \n",
    "        elif self.method == 'zscore':\n",
    "            Z = np.abs(stats.zscore(X))\n",
    "            return X[(Z < self.multiplier).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543deab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalToNumerical():\n",
    "    def __init__(self):\n",
    "        self.columns = None\n",
    "        self.mapping = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        for col in X.columns:\n",
    "            if X[col].dtype == 'object':\n",
    "                values = list(set(X[col]))\n",
    "                self.mapping[col] = {val:i for i, val in enumerate(values)}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            if col in self.mapping:\n",
    "                X[col] = X[col].apply(lambda x: self.mapping[col].get(x, -1))\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f520877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class TrainTestSplitCV():\n",
    "    def __init__(self, test_size=0.2, random_state=None):\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9252100",
   "metadata": {},
   "source": [
    "###### Defining the node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65a9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        ''' constructor ''' \n",
    "        \n",
    "        # for decision node\n",
    "        self.feature_index = feature_index #the index of the feature that this node splits on\n",
    "        self.threshold = threshold #the threshold value used to split the data at this node\n",
    "        self.left = left #the left child of this node\n",
    "        self.right = right #the right child of this node\n",
    "        self.info_gain = info_gain #the information gain obtained by splitting the data at this node\n",
    "        \n",
    "        # for leaf node\n",
    "        self.value = value #the predicted value of the target variable at this node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeade68",
   "metadata": {},
   "source": [
    "###### Defining the DecisionTreeClaasifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0247b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        ''' The __init__() function is the constructor of the DecisionTreeClassifier class. It takes two parameters:\n",
    "\n",
    "            min_samples_split: the minimum number of samples required to split a node\n",
    "            max_depth: the maximum depth of the tree '''\n",
    "        \n",
    "        # initialize the root of the tree \n",
    "        self.root = None\n",
    "        \n",
    "        # stopping conditions\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        ''' recursive function to build the tree ''' \n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]#The X and Y variables represent the features and the target variable of the dataset\n",
    "        num_samples, num_features = np.shape(X)#number of samples and features in the dataset\n",
    "        \n",
    "        # split until stopping conditions are met\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # find the best split\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # check if information gain is positive\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                # recur left\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # recur right\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                # return decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        \n",
    "        # compute leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # return leaf node\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        ''' function to find the best split '''\n",
    "        \n",
    "        # dictionary to store the best split\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        # loop over all the features\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # loop over all the feature values present in the data\n",
    "            for threshold in possible_thresholds:\n",
    "                # get current split\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # compute information gain\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y)\n",
    "                    # update the best split if needed\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "                        \n",
    "        # return best split\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        ''' the split method is used to split the dataset into two subsets based on a given threshold value and a feature index. It takes the following parameters:\n",
    "\n",
    "            dataset: The dataset to split.\n",
    "            feature_index: The index of the feature to split on.\n",
    "            threshold: The threshold value to split on.'''\n",
    "        \n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])#contains all the rows where the feature value is less than or equal to the threshold\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def information_gain(self, parent, l_child, r_child):\n",
    "        ''' function to compute information gain '''\n",
    "        # calculate entropy of parent node\n",
    "        parent_entropy = self.entropy(parent)\n",
    "    \n",
    "        # calculate entropy of left child node\n",
    "        left_entropy = self.entropy(l_child)\n",
    "        \n",
    "        # calculate entropy of right child node\n",
    "        right_entropy = self.entropy(r_child)\n",
    "    \n",
    "        # calculate weighted average entropy of child nodes\n",
    "        child_entropy = (len(l_child)/len(parent))*left_entropy + (len(r_child)/len(parent))*right_entropy\n",
    "    \n",
    "        # calculate information gain\n",
    "        gain = parent_entropy - child_entropy\n",
    "    \n",
    "        return gain\n",
    "\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        ''' function to compute entropy '''\n",
    "        \n",
    "        class_labels = np.unique(y)#gets an array of unique class labels in the set of samples.\n",
    "        entropy = 0 #This initializes the entropy variable to zero.\n",
    "        for cls in class_labels: #loops over each class label in the array of unique class labels.\n",
    "            p_cls = len(y[y == cls]) / len(y) #calculates the probability of a sample \n",
    "            entropy += -p_cls * np.log2(p_cls) \n",
    "        return entropy\n",
    "    \n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        ''' function to compute leaf node '''\n",
    "        \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)#calculates the majority class label for a leaf node\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "    \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "    \n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "    \n",
    "        else:\n",
    "            print(\"X\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "        \n",
    "            print(indent + \"left: \", end=\"\")\n",
    "            self.print_tree(tree.left, indent + \" \")\n",
    "        \n",
    "            print(indent + \"right: \", end=\"\")\n",
    "            self.print_tree(tree.right, indent + \" \")\n",
    "\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ''' function to train the tree '''\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' function to predict the class labels '''\n",
    "        # convert X to numpy array\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        \n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        ''' function to traverse the tree and make predictions '''\n",
    "        \n",
    "        # leaf node\n",
    "        if tree.value != None:\n",
    "            return tree.value\n",
    "        \n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8409b951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price  ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120          1   42   \n",
       "1  11.22        111      48           16         260     83          0   65   \n",
       "2  10.06        113      35           10         269     80          2   59   \n",
       "3   7.40        117     100            4         466     97          2   55   \n",
       "4   4.15        141      64            3         340    128          1   38   \n",
       "\n",
       "   Education  Urban  US  \n",
       "0         17      1   1  \n",
       "1         10      1   1  \n",
       "2         12      1   1  \n",
       "3         14      1   1  \n",
       "4         13      1   0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce088fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db7854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing data set\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ffb99c",
   "metadata": {},
   "source": [
    "###### Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f3e632b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class HyperparameterFinder():\n",
    "    def __init__(self, max_depth_values, min_samples_split_values):\n",
    "        self.max_depth_values = max_depth_values\n",
    "        self.min_samples_split_values = min_samples_split_values\n",
    "        self.best_hyperparameters = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Find the best hyperparameters using the find_best_hyperparameters function\n",
    "        best_hyperparameters, best_accuracy = self.find_best_hyperparameters(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        # Store the best hyperparameters\n",
    "        self.best_hyperparameters = best_hyperparameters\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Create a new decision tree classifier with the best hyperparameters\n",
    "        dt = DecisionTreeClassifier(max_depth=self.best_hyperparameters['max_depth'], min_samples_split=self.best_hyperparameters['min_samples_split'])\n",
    "\n",
    "        # Fit the decision tree on the entire training dataset\n",
    "        dt.fit(X, y)\n",
    "\n",
    "        # Return the predictions on the entire dataset\n",
    "        return dt.predict(X), self.best_hyperparameters\n",
    "    \n",
    "    def find_best_hyperparameters(self, X_train, y_train, X_test, y_test):\n",
    "        hyperparameters = {'max_depth': None, 'min_samples_split': None}\n",
    "        best_accuracy = 0.0\n",
    "\n",
    "        for max_depth in self.max_depth_values:\n",
    "            for min_samples_split in self.min_samples_split_values:\n",
    "                # Create a new decision tree classifier with the current hyperparameters\n",
    "                dt = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "\n",
    "                # Fit the decision tree on the training dataset\n",
    "                dt.fit(X_train, y_train)\n",
    "\n",
    "                # Evaluate the decision tree on the testing dataset\n",
    "                y_pred = dt.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                # Check if the current hyperparameters are better than the previous best hyperparameters\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    hyperparameters['max_depth'] = max_depth\n",
    "                    hyperparameters['min_samples_split'] = min_samples_split\n",
    "\n",
    "                # Print the current hyperparameters and accuracy for debugging\n",
    "                print(f\"max_depth={max_depth}, min_samples_split={min_samples_split}, accuracy={accuracy}\")\n",
    "\n",
    "        # Print the best hyperparameters and accuracy for debugging\n",
    "        print(f\"best_hyperparameters={hyperparameters}, best_accuracy={best_accuracy}\")\n",
    "\n",
    "        return hyperparameters, best_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b16a78d",
   "metadata": {},
   "source": [
    "###### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71cd881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f6a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "595e3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    ('outlier_treatment', OutlierTreatment()),\n",
    "     ('encoder', CategoricalToNumerical())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "28044c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANANTHU\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: Downcasting integer-dtype results in .where is deprecated and will change in a future version. To retain the old behavior, explicitly cast the results to the desired dtype.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('outlier_treatment',\n",
       "                 <__main__.OutlierTreatment object at 0x000001C35AD41A90>),\n",
       "                ('encoder',\n",
       "                 <__main__.CategoricalToNumerical object at 0x000001C35AD417F0>)])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline.fit(company_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a2219fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categorical columns\n",
    "categorical_cols = ['ShelveLoc', 'Urban','US']\n",
    "\n",
    "# create an instance of CategoricalToNumerical transformer\n",
    "cat_to_num_transformer = CategoricalToNumerical()\n",
    "\n",
    "# fit the transformer to the training data\n",
    "cat_to_num_transformer.fit(company_data[categorical_cols])\n",
    "\n",
    "# transform the categorical columns in the training and test data\n",
    "company_data[categorical_cols] = cat_to_num_transformer.transform(company_data[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1be228bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([   \n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('hyper-parameter', HyperparameterFinder(max_depth_values=[2, 4, 6, 8, 10], min_samples_split_values=[2, 4, 6, 8, 10])),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b6f20066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data to X and y\n",
    "X=company_data.drop(labels='ShelveLoc',axis=1)\n",
    "y=company_data[['ShelveLoc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12a448d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model using the pipeline\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b118e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('outlier_treatment',\n",
       "                                  <__main__.OutlierTreatment object at 0x000001C35ACB99A0>),\n",
       "                                 ('encoder',\n",
       "                                  <__main__.CategoricalToNumerical object at 0x000001C35ACB9610>)])),\n",
       "                ('dt',\n",
       "                 <__main__.DecisionTreeClassifier object at 0x000001C35AD1E520>)])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a6bd86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d3975833",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "456cefbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions using accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12670e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
